### 1.1 카프카의 탄생
##### 링크드인
* 아키텍처가 거대해짐
* 소스 애플리케이션과 타깃 애플리케이션의 개수가 증가
* 데이터를 전송하는 라인이 복잡해짐
* 소스애플리케이션과 타깃 애플리케이션을 연결하는 파이프라인 개수가 증가 -> 소스코드 및 버전관리에서 이슈 생김
* 타깃 애플리케이션에 장애 발생 하면 그 영향이 그대로 소스 애플리케이션에 전달

##### 카프카
* 장점
  * 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙 집중화함.
  * 취합한 데이터 스트림을 한 곳에서 실시간으로 관리할 수 있게 됨.
  * 카프카를 중앙에 배치함으로써 소스 애플리케이션과 타깃 애플리케이션 사이의 의존도를 최소화.
  * 이제 소스 애플리케이션에서 생성되는 데이터는 어느 타깃 애플리케이션으로 보낼 것인지 고민할 필요 없이 카프카로 넣으면 됨.
* 카프카 내부
  * 파티션
    * 데이터가 저장되는 곳
    * 동작
      * FIFO(First In First Out)
      * 프로듀서 : 데이터를 보내는 것
      * 컨슈머 : 데이터를 가져가는 것
    * 데이터 포맷 : 사실상 제한 없음.
      * 직렬화, 역직렬화를 통해 ByteArray로 통신하기 때문에 자바에서 선언 가능한 모든 객체를 지원
      * 카프카 클라이언트에서는 기본적으로 제공되는 타입 뿐만 아니라 커스텀도 상속을 받아 개발하여 사용 가능
* 카프카 상용환경
  * 최소 3대 이상의 서버(브로커)에서 분산 운영하여 프로듀서를 통해 전송받은 데이터를 파일 시스템에 안전하게 기록
  * 서버 중 일부에서 장애가 발생을 해도 데이터를 지속적으로 복제하기 때문에 안전하게 운영 가능
  * 데이터를 묶음 단위로 처리하는 배치 전송을 통해 낮은 지연과 높은 데이터 처리량도 가지게 됨.

### 1.2 빅데이터 파이프라인에서 카프카의 역할
##### 빅데이터
* 구글 데이터 센터에 보관된 데이터양 = 최소 15엑사바이트(Exabyte, EB)
* 데이터의 종류
  * 스키마 기반의 정형 데이터
  * 비정형 데이터(그림, 영상, 음성)
##### 데이터 레이크(data lake)
* 빅데이터를 저장하고 활용하기 위해서는 '일단 생성되는 데이터를 모두 모으는 것이 중요'
* 데이터가 모이는 저장 공간 
* != '데이터 웨어하우스(필터링 되거나 패키지화된 데이터 취급) -> 모든 데이터를 취급
* 엔드 투 엔드(end-to-end)
  * 일반적으로 우리가 DB에 저장하는 방식?
  * 서비스가 비대해지면 문제가 발생
  * 해결하기 위해서는 데이터를 추출하고 변경, 적재하는 과정을 묶은 데이터 파이프라인을 구축해야 한다.

##### 데이터 파이프라인
* 엔드 투 엔드 방식의 데이터 수집 및 적재를 개선하고 안전성을 추구하며, 유연하면서도 확장 가능하게 자동화한 것을 말함.
* 데이터 파이프라인을 구축하지 않고 일회성으로 구축한 데이터 수집은 결국 데이터 흐름의 파편화로 이어짐.
  * 반복적인 유지보수를 필요로 하기 때문에 기술 부채로 계속 남아 지속적으로 개발자들을 괴롭힘

##### 데이터 파이프라인에 적합한 카프카
* 높은 처리량
  * 동일한 양의 데이터를 보낼 때 네트워크 통신 횟수를 최소한으로 줄인다면, 동일 시간 내에 더 많은 데이터를 전송할 수 있음.
  * 카프카는 데이터를 묶음 단위로 처리하는 배치로 빠르게 처리할 수 있기 때문에 대용량의 실시간 로그데이터를 처리하는 데에 적합
  * 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬 처리할 수 있음.(파티션 개수 만큼 컨슈머의 개수를 늘려 데이터 처리량을 늘림)
* 확장성
  * 가변적인 환경에서 안정적으로 확장 가능하도록 설계되어 있음
  * 데이터가 적을 때 : 카프카 클러스터의 브로커를 최소한의 개수로 운영
  * 데이터가 많아질 때 : 클로스터의 브로커 개수를 자연스럽게 늘려 스케일 아웃이 가능
  * 스케일 인, 아웃 과정이 클러스터의 무중단 운영을 지원하기에 24시간 데이터 처리 가능
* 영속성
  * 데이터를 생성한 프로그램이 종료되더라도 사라지지 않은 데이터의 특성을 뜻함
  * 카프카는 전송 받은 데이터를 메모리에 저장하지 않고 파일 시스템에 저장
  * How 
    * 운영체제에서는 파일 I/O 성능 향상을 위해 페이지 캐시 영역을 메모리에 따로 생성하여 사용
    * 페이지 캐시 영역을 사용하여 한 번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하는 방식으로 진행
    * 덕분에 카프카가 파일 시스템에 저장하고 데이터를 저장, 전송하더라도 처리량이 높음
  * 추가로 디스크 기반의 파일 시스템을 활용하기에 브로커 애플리케이션이 장애 발생으로 종료되더라도 프로세스를 재시작하여 안전하게 데이터를 다시 처리할 수 있음.
* 고가용성
  * 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리 가능
  * 복제
    * 프로듀서로 전송받은 데이터를 여러 브로커 중 1대의 브로커에만 저장하는 것이 아니라 또 다른 브로커에도 저장
    * 한 브로커에 장애가 발생해도 복제된 데이터가 나머지 브로커에 저장되어 있어 지속적인 데이터 처리가 가능
  * 추가로 서버를 직접 운영하는 온프레미스(on-premise) 환경의 서버 랙 또는 퍼블릭 클라우드의 리전 단위 장애에도 데이터 복제 가능

### 1.3 데이터 레이크 아키텍처와 카프카의 미래
##### 데이터 레이크 아키텍처의 역사
1. 람다 아키텍처
  * 레거시 데이터 수집 플랫폼을 개선하기 위해 구성한 아키텍처
  * 레거시 데이터 플랫폼 아키텍처
    * 데이터를 배치로 모았으나 그 구조가 유연하지 못함
    * 실시간으로 생성되는 데이터들에 대한 인사이트를 서비스 애플리케이션에 빠르게 전달하지 못함
    * 원천 데이터로부터 파생된 데이터의 히스토리 파악이 어려움
    * 계속되는 데이터 가공으로 인해 데이터가 파편화되면서 데이터 거버넌스(데이터 표준 및 정책)를 지키기 어려움
  * 람다 아키텍처
    * 위의 단점을 해결하기 위해 스피드 레이어라고 불리는 실시간 데이터 ETL 작업 영역을 정의한 아키텍처
    * 레이어
      * 배치레이어 : 배치 데이터를 모아서 특정 시간, 타이밍마다 일괄 처리
      * 서빙레이어 : 가공된 데이터를 데이터 사용자, 서비스 애플리케이션이 사용할 수 있도록 데이터가 저장된 공간
      * 스피드레이어 : 서비스에서 생성되는 원천 데이터를 실시간으로 분석하는 용도
2. 카파 아키텍처