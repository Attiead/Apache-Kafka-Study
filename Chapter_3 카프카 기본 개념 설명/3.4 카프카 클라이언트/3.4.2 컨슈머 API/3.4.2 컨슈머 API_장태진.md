컨슈머 API
==
프로듀서가 전송한 데이터는 카프카 브로커에 적재된다.

컨슈머는 적재된 데이터를 브로커로부터 가져와서 필요한 처리를 한다.

오토 커밋 카프카 컨슈머 애플리케이션 생성.

```java
package org.example;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class SimpleConsumer {
    private final static Logger logger = LoggerFactory.getLogger(SimpleConsumer.class);
    private final static String TOPIC_NAME = "test";
    //생성한 레코드를 전송하기 위해 토픽을 지정해야함. Producer Record 인스턴스 생성에 사용.
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";
    //가져올 클러스터 서버의 host, IP를 지정함.
    
    private final static String GROUP_ID = "test-group";
    //컨슈머 그룹 이름을 선언. email이면 email-application-group. 
    //컨슈머 그룹을 기준으로 옵셋을 관리하기 때문에 선언하지 않으면 어떤 그룹에도 속하지 않는 컨슈머로 동작하게됨.

    public static void main(String[] args) {
        Properties configs = new Properties();
        //KafkaConsumer 인스턴스 생성을 위한 컨슈머 옵션 지정.
        configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);

        configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);

        //메시지 키, 값을 위한 역직렬화 클래스 선언.
        configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

        //consumer 인스턴스를 통해 데이터를 가져옴.
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
        
        //consumer에게 토픽을 할당하기 위해 subscribe 사용. Collection타입의 String을 받음. 1개이상. 
        consumer.subscribe(Arrays.asList(TOPIC_NAME));
        
        
        while(true) {
            //duration은 버퍼에 데이터를 기다리기 위한 타임아웃 간격을 뜻한다.
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            for (ConsumerRecord<String, String> record : records) {
                logger.info("{}", record);
            }
        }

    }
}

```

컨슈머 중요개념
--
컨슈머 운영방법

1. 1개 이상의 컨슈머로 이루어진 컨슈머 그룹 운영
- 컨슈머를 각 컨슈머 그룹으로 부터 격리된 환경에서 안정하게 운영할 수 있도록 도와주는 카프카의 독특한 방식.
- 토픽의 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있음.
- 1개의 컨슈머는 N개의 파티션에 할당될 수 있음. 
- 컨슈머 그룹의 컨슈머 개수는 토픽의 파티션 개수보다 같거나 작아야 한다.
- 3개의 파티션을 4개의 컨슈머로 이루어진 그룹으로 운영한다면 1개의 컨슈머는 유휴 상태로 스레드만 차지하게됨.


>동기 로직으로 돌아가는 에이전트 애플리케이션
> 실시간 리소스를 시간순으로 확인하기 위해 엘라스틱서치에 데이터를 저장하고, 대용량 적재를 위해 하둡에 적재함.
> 이때, 두 곳에 적재를 위해 동기적으로 적재를 요청하고, 동기로 실행되는 에이전트는 둘 중 장애가 발생하면 적재불능상태임.

카프카는 최종 적재되는 저장소의 장애에 유연하게 대응할 수 있도록 각기 다른 저장소에 저장하는 컨슈머를 다른 컨슈머 그룹으로 묶음.<br>
-> 각 저장소의 장애에 격리됨.

데이터 파이프라인 운영 시 적절히 컨슈머 그룹을 분리하여 운영하는 것은 매우 중요함. 

엘라스틱 서치 컨슈머 그룹이 파티션과 매칭되어 데이터를 가져가고 적재.
하둡 적재 컨슈머 그룹이 파티션과 매칭되어 데이터를 가져가고 적재함.

토픽의 데이터는 컨슈머가 가져간다해서 제거되지 않기 때문에 여러곳에서 가져갈 수 있기 때문.

> 컨슈머 그룹의 일부 컨슈머에 장애가 발생한다면?

해당 컨슈머에 할당된 파티ㅕㄴ은 장애가 발생하지 않은 다른 컨슈머에 소유권이 넘어간다. -> 리밸런싱

리밸런싱은<br>
- 컨슈머 추가 
- 컨슈머 제외의 상황
에서 발생한다. 

리밸런싱은 컨슈머가 데이터를 처리하는 도중에 발생할 수 있으므로 데이터 처리 중 발생한 리밸런싱에 대응하는 코드를 작성해야함.

리밸런싱은 자주 일어나면 안됨. -> 파티션의 소유권을 컨슈머로 재할당하는 과정에서 해당 컨슈머 그룹의 컨슈머들이 토픽의 데이터를 읽을 수 없기 때문.

특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇번째 가져가는지는 __consumer_offsets 에 기록된다. 
-> 오프셋 커밋이 기록되지 못했다면 데이터 처리 중복이 발생하기 때문에 컨슈머 애플리케이션이 오프셋 커밋을 정상적으로 처리했는지 검증해야만 한다.

> 기본 옵션은 poll() 메서드 실행시 offset commit하도록 enable.auto.commit=true로 설정되어 있음.
> auto.commit.interval.ms에 설정된 값과 같이 사용되며 해당 설정값 이상 지났을 때 그 시점까지 읽을 레코드의 오프셋을 커밋함.

poll 메서드 호출 이후 리밸런싱 또는 컨슈머 강제 종료 발생 시 컨슈머가 처리하는 데이터가 중복 또는 유실될 수 있는 가능성이 취약한 구조를 가짐.<br>
데이터 중복이나 유실을 허용하지 않는 서비스라면 자동 커밋을 사용하면 안됨.

> poll 메서드 호출 이후 데이터 처리 완료 시 commitSync() 메서드 호출.
> poll메서드를 통해 반환된 레코드의 가장 마지막 오프셋을 기준으로 커밋을 수행함. 
> 정상처리 응답까지 기다리는데 컨슈머의 처리량에 영향을 끼침. 
> 이를 해결하기 위해 commitAsync()를 사용. 
> 비동기 커밋은 실패했을 경우 현재 처리중인 데이터의 순서를 보장하지 않으며 데이터의 중복처리가 발생함.

컨슈머의 내부구조
--
poll 메서드를 호출하는 시점에 데이터를 가져오는 것이 아님.

컨슈머 애플리케이션 실행시 내부에서 Fetcher 인스턴스가 생성되어 poll 호출 전 레코드를 내부 큐로 가져옴. <br>
이후에 명시적으로 poll 호출 시 내부 큐에 있는 레코드를 반환받아 처리함.

주요 옵션
--
- bootstrap.servers
- key&value.deserializer

선택 옵션
--
group.id 등등..

동기 오프셋 커밋
--
```java
configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        while(true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            for (ConsumerRecord<String, String> record : records) {
                logger.info("{}", record);
            }
            //poll 메서드로 받은 가장 마지막 레코드의 오프셋을 기준으로 커밋함.
            consumer.commitSync();
        }
```

브로커로부터 컨슈머 오프셋 커밋이 완료되었음을 받기까지 컨슈머는 데이터를 더 처리하지 않고 기다리기때문에<br>
비동기보다 동일 시간당 데이터 처리량이 적다는 특징이 있음.

개별 레코드 단위로 매번 오프셋 커밋을 하고 싶다면,

```java
        while(true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            
            Map<TopicPartition, OffsetAndMetadata> currentOffset = new HashMap<>();
            
            for (ConsumerRecord<String, String> record : records) {
                logger.info("{}", record);
                currentOffset.put(
                        new TopicPartition(record.topic(), record.partition()),
                        new OffsetAndMetadata(record.offset() + 1, null));
            //poll 메서드로 받은 가장 마지막 레코드의 오프셋을 기준으로 커밋함.
            consumer.commitSync(currentOffset);
        }
```

비동기 오프셋 커밋
--
```java
        while(true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            for (ConsumerRecord<String, String> record : records) {
                logger.info("{}", record);
            }
            //poll 메서드로 받은 가장 마지막 레코드의 오프셋을 기준으로 커밋함.
            consumer.commitAsync();
        }
```

동기 오프셋과 다른점은 커밋이 완료될 때까지 응답을 기다리지 않음.<br>
비동기로 커밋 응답을 받기 때문에 callback 함수를 파라미터로 받아서 결과를 얻을 수 있음. 

```java
consumer.commitAsync(new OffsetCommitCallback() {
    public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception e) {
        if (e! = null)
            System.err.println("Commit failed");
        else
            System.out.println("Commit succeeded");
        if (e != null) 
            logger.error("Commit failed for offsets {}", offsets, e);
    }
});
```
OffsetCommitCallback은 commitAsync() 응답을 받을 수 있도록 도와주는 콜백 인터페이스.
정상 커밋시 exception 변수는 null. 옵셋정보가 Map에 포함되어 있음. 

리밸런스 리스너를 가진 컨슈머
--
poll 메서드를 통해 반환받은 데이터를 모두 처리하기 전에 리밸런스가 발생하면 데이터를 중복 처리할 수 있다.

데이터를 중복 처리하지 않기 위해서는 리밸런스 발생시 처리한 데이터를 기준으로 커밋을 시도해야함. 
ConsumerRebalanceListener 인터페이스를 지원함.

```java
package org.example;

import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.time.Duration;
import java.util.*;

public class SimpleConsumer {
    private final static Logger logger = LoggerFactory.getLogger(SimpleConsumer.class);
    private final static String TOPIC_NAME = "test";
    //생성한 레코드를 전송하기 위해 토픽을 지정해야함. Producer Record 인스턴스 생성에 사용.
    private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";
    //가져올 클러스터 서버의 host, IP를 지정함.

    private final static String GROUP_ID = "test-group";
    //컨슈머 그룹 이름을 선언. email이면 email-application-group.
    //컨슈머 그룹을 기준으로 옵셋을 관리하기 때문에 선언하지 않으면 어떤 그룹에도 속하지 않는 컨슈머로 동작하게됨.

    public static void main(String[] args) {
        Properties configs = new Properties();
        //KafkaConsumer 인스턴스 생성을 위한 컨슈머 옵션 지정.
        configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);

        configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);

        //메시지 키, 값을 위한 역직렬화 클래스 선언.
        configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

        //consumer 인스턴스를 통해 데이터를 가져옴.
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);

        //consumer에게 토픽을 할당하기 위해 subscribe 사용. Collection타입의 String을 받음. 1개이상.
        consumer.subscribe(Arrays.asList(TOPIC_NAME), new RebalanceListener());

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

            Map<TopicPartition, OffsetAndMetadata> currentOffset = new HashMap<>();

            for (ConsumerRecord<String, String> record : records) {
                logger.info("{}", record);
                currentOffset.put(
                        new TopicPartition(record.topic(), record.partition()),
                        new OffsetAndMetadata(record.offset() + 1, null));
                //poll 메서드로 받은 가장 마지막 레코드의 오프셋을 기준으로 커밋함.
                consumer.commitSync(currentOffset);
            }
        }
    }
    private static class RebalanceListener implements ConsumerRebalanceListener {
            public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
                logger.warn("Partitions are assigned");
            }
            public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
                logger.warn("Partitions are revoked");
                consumer.commitSync(currentOffsets);
            }
    }
    
}

```

파티션 할당 컨슈머
--
subscribe() 메서드를 사용하여 구독 형태로 사용하는 것 외에도 직접 파티션을 컨슈머에 명시적으로 할당해서 운영 가능.

컨슈머가 어떤 토픽, 파티션을 할당할지 명시적으로 선언할 때는 assign()메서드를 사용.

```java
public class kafkaConsumerExactPartition() {
    public static void main(String[] args) {
        String TOPIC_NAME = "test";
        int PARTITION_NUMBER = 0;
        
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
        consumer.assign(Collections.singletons(new TopicPartition(TOPIC_NAME, PARTITION_NUMBER)));
        
        while(true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
            for (ConsumerRecord<String, String> record : records) {
                ...
            }
        }
    }
}
```

컨슈머에 할당된 파티션 확인 방법
--
토픽과 파티션에 대한 정보는 assignment()메서드로 확인.<br>
```java
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
consumer.subscribe(Arrays.asList(TOPIC_NAME));
Set<TopicPartition> assignedTopicPartition = consumer.assignment();
```

컨슈머의 안전한 종료
--

정상적으로 종료되지 않은 컨슈머는 세션타임아웃이 발생할 때까지 컨슈머 그룹에 남게됨

실제로 종료되었지만 동작을 하지 않는 컨슈머가 존재하기 때문에 파티션의 데이터는 소모되지 못하고 컨슈머 렉이 늘어남.<br>
-> 랙이 늘어나면 데이터 처리 지연이 발생하게 됨.

KafkaConsumer 클래스의 wakeup() 메서드를 이용하여 종료.<br>
wakeup이후 poll이 호출되면 WakeupException 예외 발생.

이후 finally { consumer.close(); } 로 안전 종료.

wakeup 메서드의 호출 시점. 
--
java의 ShutdownThread(ShutdownHook) 시점에 consumer.wakeup으로 사용.<br>

실행중인 애플리케이션에 kill -TERM {프로세스 번호}를 호출하여 셧다운 훅을 발생시킬 수 있고, 이때 ShutdownTread가 실행되면서 wakeup()을 호출되게 할 수 있음.