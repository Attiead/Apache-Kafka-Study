스프링 카프카
==

- 카프카를 스프링 프레임워크에서 효과적으로 사용할 수 있도록 만들어진 라이브러리
- 기존 카프카 클라이언트 라이브러리를 래핑하여 만든 스프링 카프카 라이브러리는 카프카 클라이언트에서 사용하는 여러가지 패턴을 미리 제공한다.

스프링 카프카 프로듀서
--
카프카 템플릿 클래스 사용

카프카 템플릿은 프로듀서 팩토리 클래스를 통해 생성

1. 기본 카프카 템플릿

application.yaml에 프로듀서 옵션을 넣고 사용. ex) spring.kafka.producer.acks 등..

기본 템플릿을 사용할 경우 기존 카프카 클라이언트에서 사용하던 필수 옵션을 빼더라도 default값으로 자동 설정된다.

default : localhost:9092 / key&value-serializer - StringSerializer

```java

@SpringBootApplication
public class SpringProducerApplication implements CommandLineRunner {

    private static String TOPIC_NAME = "test";

    @Autowired
    private KafkaTemplate<Integer, String> template;

    public static void main(String[] args) {
        SpringApplication application = new SpringApplication(SpringProducerApplication.class);
        application.run(args);
    }

    @Override
    public void run(String... args) {
        for (int i = 0 ; i < 10 ; i++) {
            template.send(TOPIC_NAME, "test" + i);
        }
        System.exit(0);
    }
}

```

2. 커스텀 카프카 템플릿

프로듀서 팩토리를 통해 만든 카프카 템플릿 객체를 빈으로 등록하여 사용하는 것.

각종 옵션을 선언하여 사용가능. 다양한 종류의 프로듀서 인스턴스를 생성하고 싶다면 이 방식을 선택. 

빈으로 등록하여 사용.

```java

@Configuration
public class KafkaTemplateConfiguration {

    @Bean
    public KafkaTemplate<String, String> customKafkaTemplate() {

        Map<String, Object> props = new HashMap<>();

        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "my-kafka:9092");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.ACKS_CONFIG, "all");

        ProducerFactory<String, String> pf = new DefaultKafkaProducerFactory<>(props);

        return new KafkaTemplate<>(pf);
    }
}

```

기본 카프카 템플릿처럼 메인 애플리케이션에서 @Autowired를 붙여서 선언하면된다. <br>
단, 빈 객체 이름과 동일하게 customKafkaTemplate을 변수명으로 선언해야함.

```java

@SpringBootApplication
public class SpringProducerApplication implements CommandLineRunner {

    private static String TOPIC_NAME = "test";

//    @Autowired
//    private KafkaTemplate<Integer, String> template;

    @Autowired
    private KafkaTemplate<String, String> customKafkaTemplate;

    public static void main(String[] args) {
        SpringApplication application = new SpringApplication(SpringProducerApplication.class);
        application.run(args);
    }

    @Override
    public void run(String... args) throws Exception {
        ListenableFuture<SendResult<String, String>> future = customKafkaTemplate.send(TOPIC_NAME, "test");
        future.addCallback(new KafkaSendCallback<String, String>() {

            @Override
            public void onSuccess(SendResult<String, String> result) {

            }

            @Override
            public void onFailure(KafkaProducerException ex) {

            }
        });
        System.exit(0);
    }

//    @Override
//    public void run(String... args) throws Exception {
//        for (int i = 0 ; i < 10 ; i++) {
//            template.send(TOPIC_NAME, "test" + i);
//        }
//        System.exit(0);
//    }
}

```

ListenableFuture 인스턴스에 addCallback 함수에 붙여 프로듀서가 보낸 데이터의 브로커 적재 여부를 비동기로 확인 할 수 있다. 

스프링 카프카 컨슈머
--

스프링 카프카의 컨슈머는 기존 컨슈머를 2개의 타입으로 나누고 커밋을 7가지로 나누어 세분화했다.

타입 : 레코드 리스너(1개의 레코드 처리), 배치 리스너(poll()메서드로 리턴받은 consumerRecord 처럼 여러개 처리)

default는 레코드 리스너임.

매뉴얼 커밋은 Acknowledging이 붙은 리스너를 <br>
Kafka Consumer 인스턴스에 직접 접근하여 컨트롤하고 싶다면 ConsumerAware가 붙은 리스너를 사용한다.

커밋 타입 : RECORD, BATCH, TIME, COUNT, COUNT_TIME, MANUAL, MANUAL_IMMEDIATE)

스프링 카프카는 커밋 대신 AckMode라고 부른다. 

default AckMode는 BATCH, enable.auto.commit : false이다.


1. 기본 리스너 컨테이너

기본 리스너 컨테이너 팩토리를 통해 생성된 리스너 컨테이너를 사용함.

application.yml에 컨슈머와 리스너 옵션을 넣고 사용함. 

주의 : 스크링 카프카에서 컨슈머를 래핑한 리스너 컨테이너가 다양한 옵션을 포함하여 동작함.<br>
기존 카프카 클라이언트에서 사용되지 않는 새로운 옵션들이기 때문에 각 옵션 사용 방법과 옵션값을 적절히 정의하고 사용해야함.

기본 옵션 : 서버 - my-kafka:9092, AckMode - MANUAL_IMMEDIATE, 리스너 타입 - RECORD로 설정

```java

@SpringBootApplication
public class SpringConsumerApplication {
    public static Logger logger = LoggerFactory.getLogger(SpringConsumerApplication.class);

    public static void main(String[] args) {
        SpringApplication application = new SpringApplication(SpringConsumerApplication.class);
        application.run(args);
    }
    
    /*
        기본 리스너 선언
        poll()이 호출되어 가져온 레코드가 차례대로 개별 레코드의 메시지 값을 파라미터로 받음.
        컨슈머레코드를 바기 때문에 메시지 키, 값에 대한 처리를 해당 메서드안에서 수행함.
     */
    @KafkaListener(topics = "test", groupId = "test-group-00")
    public void recordListener(ConsumerRecord<String, String> record) {
        logger.info(record.toString());
    }

    /*
        메시지 값을 파라미터로 받는 리스너
        String 클래스로 메시지 값을 전달받음
     */
    @KafkaListener(topics = "test", groupId = "test-group-01")
    public void singleTopicListener(String messageValue) {
        logger.info(messageValue);
    }    
    
    /*
        개별 리스너에 카프카 컨슈머 옵션값을 부여하는 방법
        propeties를 사용.
     */
    @KafkaListener(topics = "test", groupId = "test-group-02", 
                    properties = {
                        "max.poll.interval.ms:60000",
                            "auto.offset.reset:earliest"
                    })
    public void singleTopicWithPropertiesListenere(String messageValue) {
        logger.info(messageValue);
    }    
    
    /*
        2개 이상의 카프카 컨슈머 스레드 실행하는 방법
        concurrency 옵션을 사용. 옵션값만큼 컨슈머 스레드를 만들어서 병렬처리함
     */
    @KafkaListener(topics = "test", groupId = "test-group-03",
                    concurrency = "3")
    public void concurrentTopicListener(String messageValue) {
        logger.info(messageValue);
    }    
    
    /*
        특정 토픽의 특정 파티션만 구독하는 방법
        topicPartitions 파라미터 사용. 
        @PartitionOffset으로 특정 파티션의 특정 오프셋까지 지정함. 그룹 아이디에 관계 없음.
     */
    @KafkaListener(topicPartitions = {
            @TopicPartition(topic = "test01", partitions = {"0", "1"}),
            @TopicPartition(topic = "test02", partitionOffsets = 
            @PartitionOffset(partition = "0", initialOffset = "3"))
        },
        groupId = "test-group-04")
    public void listenSpecificPartitoins(ConsumerRecord<String, String> record) {
        logger.info(record.toString());
    }
}

```


2. 배치 리스너

리스너 타입 - BATCH로 설정

```java

@SpringBootApplication
public class SpringConsumerApplication {
    public static Logger logger = LoggerFactory.getLogger(SpringConsumerApplication.class);

    public static void main(String[] args) {
        SpringApplication application = new SpringApplication(SpringConsumerApplication.class);
        application.run(args);
    }
    
    /*
        컨슈머 레코드의 묶음을 파라미터로 받음
        컨슈머레코드를 받기 때문에 메시지 키, 값에 대한 처리를 해당 메서드안에서 수행함.
     */
    @KafkaListener(topics = "test", groupId = "test-group-01")
    public void batchListener(ConsumerRecord<String, String> records) {
        records.forEach(record -> logger.info(record.toString()));
    }

    /*
        메시지 값을 List 자료구조로 처리
     */
    @KafkaListener(topics = "test", groupId = "test-group-02")
    public void batchListener(List<String> list) {
        list.forEach(recordValue -> logger.info(recordValue));
    }    
    
    /*
        2개 이상의 컨슈머 스레드로 배치 리스너 사용시.
     */
    @KafkaListener(topics = "test", groupId = "test-group-03", 
                    concurrency = "3")
    public void concurrentBatchListener(ConsumerRecord<String, String> records) {
        records.forEach(record -> logger.info(record.toString()));
    }    
    
}

```

3. 배치 컨슈머 리스너 & 배치 커밋 리스너

둘 다 배치 타입으로 선언된 리스너. 

배치 컨슈머 리스너 : 컨슈머 직접사용을 위해 컨슈머 인스턴스를 파라미터로 받음.<br>
배치 커밋 리스너 : 컨테이너에서 관리하는 AckMode 사용을 위해 Acknowledgement 인스턴스를 파라미터로 받음.

컨슈머 인스턴스를 사용하면 동기&비동기 커밋을 사용할 수 있다.<br>
-> 사용하려면 배치 컨슈머 리스너를 사용하면 됨. 

둘다 사용하고 싶다면 [배치 커밋 컨슈머 리스너]를 사용하면 됨.<br>
AckMode - MANUAL_IMMEDIATE를 사용.


```java

@SpringBootApplication
public class SpringConsumerApplication {
    public static Logger logger = LoggerFactory.getLogger(SpringConsumerApplication.class);

    public static void main(String[] args) {
        SpringApplication application = new SpringApplication(SpringConsumerApplication.class);
        application.run(args);
    }

    /*
        수동 커밋을 위해 Acknowledgment 인스턴스 받음. 
        AckMode는 MANUAL or MANUAL_IMMEDIATE로 설정
     */
    @KafkaListener(topics = "test", groupId = "test-group-01")
    public void commitListener(ConsumerRecords<String, String> records, Acknowledgment ack) {
        records.forEach(record -> logger.info(record.toString()));
        ack.acknowledge();
    }

    /*
        동기 커밋, 비동기 커밋을 사용하여 원하는 타이밍에 커밋할 수 있게 로직 추가 가능. 
        AckMode는 MANUAL or MANUAL_IMMEDIATE로 설정
     */
    @KafkaListener(topics = "test", groupId = "test-group-02")
    public void consumerCommitListener(ConsumerRecords<String, String> records, 
                                       Consumer<String, String> consumer) {
        records.forEach(record -> logger.info(record.toString()));
        consumer.commitAsync();
    }

}

```

4. 커스텀 리스너 컨테이너

서로 다른 설정을 가진 2개 이상의 리스너를 구현하거나 리밸런스 리스너를 구현하기 위해 사용.

카프카 리스너 컨테이너 팩토리 인스턴스를 생성해서 빈으로 등록하여 사용함. 

```java

@Configuration
public KafkaListenerContainerFactory<ConcurrentMessageListenerContainer<String, String>> customContainerFactory() {
    
    //props 설정
        
        //컨슈머 옵션값을 받는 인스턴스 생성. 컨슈머 기본 옵션을 설정하는 용도로 사용됨.
        DefaultKafkaConsumerFactory cf = new DefaultKafkaConsumerFactory<>(props);
        
        //2개 이상의 컨슈머 리스너를 만들때 사용
        ConcurrentKafkaListenerContainerFactory<String, String> factory = new ConcurrentKafkaListenerContainerFactory<>();
        
        //리밸런스 리스너 선언. 
        factory.getContainerProperties().setConsumerRebalanceListener(new ConsumerAwareRebalanceListener() {
            @Override
            public void onPartitionsRevokeBeforeCommit(Consumer<?, ?> consumer, Collection<TopicPartiton> partitions) {
                
            }
            //등등 파티션 설정
        });
        
        //레코드 리스너 사용함을 명시하기 위해 false사용. 배치 리스너를 사용한다면 true
        factory.setBatchListener(false);
        
        //레코드 단위 커밋을 위해 RECORD로 설정
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.RECORD);
        
        //컨슈머 팩토리에 컨슈머 설정값 인스턴스 설정.
        factory.setConsumerFactory(cf);
        return factory;
        
}


@SpringBootApplication
        ...

    //containerFactory 옵션을 커스텀 컨테이너 팩토리로 설정. 빈객체로 등록한 이름을 옵션값으로 설정하면 커스텀 리스너 컨테이너 사용가능!
    @KafkaListener(topics = "test", groupId = "test-group", containerFactory = "customContainerFactory")
    public void customListener(String data) {
        logger.info(data);
    }
    
    
```


정리 
--

다 알아 보았음. 개념을 잘 이해하고 써야 파이프라인을 최적화하고 한정된 리소스에서 최고의 성능을 내도록 설정할 수 있음.